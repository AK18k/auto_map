{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AK18k/auto_map/blob/main/AUTOMAP_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "common code\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mpFKw7Dy-ri8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AK18k/auto_map"
      ],
      "metadata": {
        "id": "P1xKrvipsdUf",
        "outputId": "2f9be4a4-f2e5-421d-979f-9d95baeedba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'auto_map'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 180 (delta 1), reused 0 (delta 0), pack-reused 174\u001b[K\n",
            "Receiving objects: 100% (180/180), 15.53 MiB | 22.24 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import cv2\n",
        "import math\n",
        "import time\n",
        "from scipy.io import loadmat\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape\n",
        "from tensorflow.keras import Model\n",
        "import glob\n",
        "from torchvision.transforms import functional as F\n",
        "from torchvision.transforms import RandomCrop\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gc"
      ],
      "metadata": {
        "id": "-ScTlc-g4bqx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWSnnH_QVRwc",
        "outputId": "a3a89a43-3b0a-4146-e2a7-0ed664586abd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the directory path\n",
        "directory = '/content/drive/MyDrive/automap/imgs'\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "file_list = os.listdir(directory)\n",
        "\n",
        "print(f'raw img count = {len(file_list)}')\n",
        "\n",
        "# Select 10 random files from the list\n",
        "selected_files = file_list[0:200]\n",
        "\n",
        "# Create a list of full paths for the selected files\n",
        "file_paths = [os.path.join(directory, filename) for filename in selected_files]\n",
        "\n",
        "print(file_paths)\n",
        "\n",
        "# # Print the filenames and their full paths\n",
        "# for filename, path in zip(random_files, file_paths):\n",
        "#     print(f\"Filename: {filename}\")\n",
        "#     print(f\"Full Path: {path}\")\n",
        "#     print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoQe1uGJVbaI",
        "outputId": "9b56c495-69c9-40a7-d16d-c0e18c8aa62e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw img count = 137\n",
            "['/content/drive/MyDrive/automap/imgs/10155709300728342918543955138521808206_f7cj92.png', '/content/drive/MyDrive/automap/imgs/10383960670432673238945376919735423432_hd3moq.png', '/content/drive/MyDrive/automap/imgs/1256842362861431725328351539259305635_u1qifz.png', '/content/drive/MyDrive/automap/imgs/10287653421930576798556842610982533460_vpbhw6.png', '/content/drive/MyDrive/automap/imgs/17517381147706809156163698942582418325_tutfbr.png', '/content/drive/MyDrive/automap/imgs/23519598294167460669966745319398153772_4fvhwr.png', '/content/drive/MyDrive/automap/imgs/17871983995291973291210205507121602296_hd8ger.png', '/content/drive/MyDrive/automap/imgs/18104280246346700713752899198427570737_ezdqyq.png', '/content/drive/MyDrive/automap/imgs/24716339483627393401392199056832608433_wtt5qq.png', '/content/drive/MyDrive/automap/imgs/10996416492353037588312781035930080694_8rstz0.png', '/content/drive/MyDrive/automap/imgs/26740916849083948015827135783885268528-2_6hkbx5.png', '/content/drive/MyDrive/automap/imgs/15606713623657301981614912219511809416_2_94v295.png', '/content/drive/MyDrive/automap/imgs/13353724432735380699905228693882625716_1tbyf9.png', '/content/drive/MyDrive/automap/imgs/16061525395627866800451108188666498463_f9mrv9.png', '/content/drive/MyDrive/automap/imgs/26740916849083948015827135783885268528_e8uwfn.png', '/content/drive/MyDrive/automap/imgs/62251368659414281768550499840080640229_8jw2hb.png', '/content/drive/MyDrive/automap/imgs/49538570955854652971715060419437210854_qfxazj.png', '/content/drive/MyDrive/automap/imgs/28679939396004151795585406073042323038_psrr3m.png', '/content/drive/MyDrive/automap/imgs/62440969118040059965044820734401488887_6hzwt0.png', '/content/drive/MyDrive/automap/imgs/47557396307760215809300057577936592627_m7mq32.png', '/content/drive/MyDrive/automap/imgs/47513502650936350354964244779459913004-3_th1gik.png', '/content/drive/MyDrive/automap/imgs/62774794894109549387630855543283311955_2_tdirok.png', '/content/drive/MyDrive/automap/imgs/33669092406557001556710892720325153219_eq21sh.png', '/content/drive/MyDrive/automap/imgs/33728467384543072824771678110722875201_f9qa0p.png', '/content/drive/MyDrive/automap/imgs/30661727075761817007267292459310975718_86nsuj.png', '/content/drive/MyDrive/automap/imgs/103416378058309979932405295235813040436_1g2pmw.png', '/content/drive/MyDrive/automap/imgs/91815015110608941073755910413288028905_kwjolc.png', '/content/drive/MyDrive/automap/imgs/100469495785351489872749036114751610212_rfyvv7.png', '/content/drive/MyDrive/automap/imgs/87180314458623865269977662447356279507_tcw56c.png', '/content/drive/MyDrive/automap/imgs/97600927297254707513662656394991173027_0k06p2.png', '/content/drive/MyDrive/automap/imgs/89871789430838637694883774745784638013_y2t9e8.png', '/content/drive/MyDrive/automap/imgs/86236188012565981583483399251510590408_2_vw97dk.png', '/content/drive/MyDrive/automap/imgs/63510470621460583865307590457045621750_wfd1y4.png', '/content/drive/MyDrive/automap/imgs/64947154984935334365130497226051564059_piq56n.png', '/content/drive/MyDrive/automap/imgs/69949397621405752847745986326314413051_wai6lj.png', '/content/drive/MyDrive/automap/imgs/62774794894109549387630855543283311955_9jbiyo.png', '/content/drive/MyDrive/automap/imgs/84856267960116899671078402865134921840_j5zwtq.png', '/content/drive/MyDrive/automap/imgs/110057948387370363009458390264986734403_myst7q.png', '/content/drive/MyDrive/automap/imgs/112456448066531979951054695594530500685_wrc6wl.png', '/content/drive/MyDrive/automap/imgs/112178367511062740933520645402062866244_5sqjdi.png', '/content/drive/MyDrive/automap/imgs/111524717177122678951114473577277787051_kt9www.png', '/content/drive/MyDrive/automap/imgs/108757234707826731622534463166732014399_zneaoc.png', '/content/drive/MyDrive/automap/imgs/108392178527872886183110835574345380047_dc2agp.png', '/content/drive/MyDrive/automap/imgs/106111337169988693038323274011777746837_0yin7u.png', '/content/drive/MyDrive/automap/imgs/111018930978236771390670303639566239985_1bnarb.png', '/content/drive/MyDrive/automap/imgs/107826458213940261956471276912177567239_9467w9.png', '/content/drive/MyDrive/automap/imgs/111016754890854009969250427027267219881_wkp0ya.png', '/content/drive/MyDrive/automap/imgs/104055072637907464008767269203861924017_huh41k.png', '/content/drive/MyDrive/automap/imgs/127193766790524852458047964184829087241_klomkd.png', '/content/drive/MyDrive/automap/imgs/120641250378848817226599591125249193787_1vwu72.png', '/content/drive/MyDrive/automap/imgs/121369866312829737404259612004787672904_od40ao.png', '/content/drive/MyDrive/automap/imgs/114041240061582113028394479929792704149_u7xmxu.png', '/content/drive/MyDrive/automap/imgs/115733055953927986967208164376379449432_li9tme.png', '/content/drive/MyDrive/automap/imgs/117503487105610561494614672580071778723_egzn5w.png', '/content/drive/MyDrive/automap/imgs/126455653911678893263056441159987922516_uz7fwy.png', '/content/drive/MyDrive/automap/imgs/115252833781991791197512509423446047187_pnh4fu.png', '/content/drive/MyDrive/automap/imgs/121982858364557665434391755127892214185_1e27fz.png', '/content/drive/MyDrive/automap/imgs/127776313362848303557368271134995152837_apvrf1.png', '/content/drive/MyDrive/automap/imgs/117922406082772720514160287292487390144_3qnpe6.png', '/content/drive/MyDrive/automap/imgs/119688533980562249677219589534851011987_60uvre.png', '/content/drive/MyDrive/automap/imgs/131603548504748381186066883008735293279_x4x4ls.png', '/content/drive/MyDrive/automap/imgs/134230638227943448483430779879455672678_nkryka.png', '/content/drive/MyDrive/automap/imgs/131241147536242919540082434604973143614_3wsmbz.png', '/content/drive/MyDrive/automap/imgs/137978876620819180655083942883406964928_so8cty.png', '/content/drive/MyDrive/automap/imgs/131648682133615188228601432675633412320_yw4cvh.png', '/content/drive/MyDrive/automap/imgs/145427013841140062478220774079107134701-2_yq5war.png', '/content/drive/MyDrive/automap/imgs/137967645291829623589025104429037566245_ty0ua4.png', '/content/drive/MyDrive/automap/imgs/133117830164386750221716087231377502440_w4gp1z.png', '/content/drive/MyDrive/automap/imgs/129242675756041973355687068645321283308_ufajm6.png', '/content/drive/MyDrive/automap/imgs/137388819814035428537164273550346941304_uaixht.png', '/content/drive/MyDrive/automap/imgs/153727633750702336351810492317390365896_iycqix.png', '/content/drive/MyDrive/automap/imgs/146381384591357414868726401545939282660_96eirs.png', '/content/drive/MyDrive/automap/imgs/145698282304700116300882843111967537977_f6qhtv.png', '/content/drive/MyDrive/automap/imgs/145769364607358984473800346357899635518_w3mh7f.png', '/content/drive/MyDrive/automap/imgs/155691603412384342537901614325751648892_2x8184.png', '/content/drive/MyDrive/automap/imgs/147856697855406216911500275209241729282_u5p8bx.png', '/content/drive/MyDrive/automap/imgs/147036015370488755117195440122198442935_gj6nyv.png', '/content/drive/MyDrive/automap/imgs/150925806630506707155140197611651038951_506rh8.png', '/content/drive/MyDrive/automap/imgs/145987248740080156691960355717233717054_fbjstn.png', '/content/drive/MyDrive/automap/imgs/152733907856972127971985724804321889809_u7ghw8.png', '/content/drive/MyDrive/automap/imgs/175993948212683701562003497511214331387_sr16co.png', '/content/drive/MyDrive/automap/imgs/157943178667978315593423977854134065828_w1j177.png', '/content/drive/MyDrive/automap/imgs/159216970546428043543933950339353602394_t0rgza.png', '/content/drive/MyDrive/automap/imgs/162648608648453851477134030640090786312_97dr7j.png', '/content/drive/MyDrive/automap/imgs/167426234824700370197428233814927580454_mgkykn.png', '/content/drive/MyDrive/automap/imgs/173480850478104643017119358503404014196_qey2vk.png', '/content/drive/MyDrive/automap/imgs/163458460465612645961271966254638198735_8tlhrq.png', '/content/drive/MyDrive/automap/imgs/174600210814713315828954104869955154340_y7nqyx.png', '/content/drive/MyDrive/automap/imgs/159364525876157332485573893353941089455_aepmh7.png', '/content/drive/MyDrive/automap/imgs/160327085026839567388469656243162554002_4rz0zs.png', '/content/drive/MyDrive/automap/imgs/174670802714657222439280962872741263127_7fupbg.png', '/content/drive/MyDrive/automap/imgs/182153357033863986819477081579951131676_yetgon.png', '/content/drive/MyDrive/automap/imgs/177242461410205305911459438621785113319_wxnhs2.png', '/content/drive/MyDrive/automap/imgs/176139149165255627395732438927565115933_2_cvhkvs.png', '/content/drive/MyDrive/automap/imgs/199072368172967010909636348828886390156_co5vik.png', '/content/drive/MyDrive/automap/imgs/220991425902150564296792633654689602163_hrvmt4.png', '/content/drive/MyDrive/automap/imgs/208665949772531573966572593951616806531_n8qw25.png', '/content/drive/MyDrive/automap/imgs/221516731243657777508708160092801128398_d8pxyz.png', '/content/drive/MyDrive/automap/imgs/185103609082807172741758831509642702963_w5om81.png', '/content/drive/MyDrive/automap/imgs/204422322492048939194499080859737112307_pjmtqu.png', '/content/drive/MyDrive/automap/imgs/207601568257371629456571671613073108105_rd3vig.png', '/content/drive/MyDrive/automap/imgs/186710864282628233004220911541749949393_sb4ype.png', '/content/drive/MyDrive/automap/imgs/245895219126534788779109786698958326807_1a9ait.png', '/content/drive/MyDrive/automap/imgs/229647061532869405127486256298724729451_o2d0lv.png', '/content/drive/MyDrive/automap/imgs/255685135940885410514594136492164638096_m86wzw.png', '/content/drive/MyDrive/automap/imgs/232572031807344965043258496995347066691_g4zxoq.png', '/content/drive/MyDrive/automap/imgs/224904318374059042978778904037988750967_dbs3bj.png', '/content/drive/MyDrive/automap/imgs/251817752826726742233508350809968475767_o1z8dd.png', '/content/drive/MyDrive/automap/imgs/234342142542575223651664904935164209557_57uem0.png', '/content/drive/MyDrive/automap/imgs/235853514537661378209836459660303802572_-bl64a.png', '/content/drive/MyDrive/automap/imgs/241628199575537995884366376583690323975_tgclgn.png', '/content/drive/MyDrive/automap/imgs/228505125625411655559042398552685461655_cvearx.png', '/content/drive/MyDrive/automap/imgs/239328921181741075231340728462151367739_z8w503.png', '/content/drive/MyDrive/automap/imgs/242212504721475153281566846983009162353_1v0l8r.png', '/content/drive/MyDrive/automap/imgs/242159935290547449788910895844948743899_pxrrfs.png', '/content/drive/MyDrive/automap/imgs/278781644981372306896738110447513784487_2z4xsa.png', '/content/drive/MyDrive/automap/imgs/287674558154154196238750035876376456720_de0kdu.png', '/content/drive/MyDrive/automap/imgs/257475948814337233640540177569885227207_jaj8iw.png', '/content/drive/MyDrive/automap/imgs/284353054075043225622260270287627142906_kduagg.png', '/content/drive/MyDrive/automap/imgs/287658295007948631772703202498743716060_3yiz93.png', '/content/drive/MyDrive/automap/imgs/289108620230468119174968226927683707287_9wupg2.png', '/content/drive/MyDrive/automap/imgs/278147989796380509519073707235611243961_lgo9hx.png', '/content/drive/MyDrive/automap/imgs/282084762366059076387208905274707563447_d4ptrb.png', '/content/drive/MyDrive/automap/imgs/269577503052282080020245006456074886585_yqub0o.png', '/content/drive/MyDrive/automap/imgs/266463130540256183061556297994476560538_jkbs4h.png', '/content/drive/MyDrive/automap/imgs/313697209576187055457395864503092360851_8joobi.png', '/content/drive/MyDrive/automap/imgs/307400577352691476839033094654629005292_2_eyg2tu.png', '/content/drive/MyDrive/automap/imgs/316310243794898186923644098315438248232_5jyw88.png', '/content/drive/MyDrive/automap/imgs/309362609894399458585188858667076734340_312chn.png', '/content/drive/MyDrive/automap/imgs/325164322016612295040208415099913503835_djqek1.png', '/content/drive/MyDrive/automap/imgs/292918128360817403765919130571877152208_3ibhhb.png', '/content/drive/MyDrive/automap/imgs/293237814606131965920904052737398761929_wo83it.png', '/content/drive/MyDrive/automap/imgs/296076958641695785561110249259065599111_tfzq7g.png', '/content/drive/MyDrive/automap/imgs/306454472377761167397878598740821355166_kvraex.png', '/content/drive/MyDrive/automap/imgs/304673909503207424801802419702123736315_vyckk1.png', '/content/drive/MyDrive/automap/imgs/335389077904052440696851091734860414013_2ukkfm.png', '/content/drive/MyDrive/automap/imgs/327043651451092435505761971551575640871_3qwimg.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def resize_images(image_paths, output_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(output_size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    resized_images = []\n",
        "\n",
        "    file_index = -1\n",
        "    for path in image_paths:\n",
        "        file_index = file_index + 1\n",
        "\n",
        "        # print(f'file {file_index}/{len(image_paths)}')\n",
        "\n",
        "        gray_image = Image.open(path)\n",
        "        # display(gray_image)\n",
        "\n",
        "        transform = transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor(),])\n",
        "        gray_tensor = transform(gray_image)\n",
        "\n",
        "        gray_tensor_squeezed = gray_tensor.squeeze(0)\n",
        "        gray_arr = gray_tensor_squeezed.numpy()\n",
        "\n",
        "        gray_arr_norm = gray_arr * 255 / np.max(gray_arr)\n",
        "        # plt.imshow(gray_arr_norm, cmap='gray')\n",
        "        # plt.title('gray_arr_norm')\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "        transform = transforms.Compose([transforms.Resize((128,128)),transforms.ToTensor(),])\n",
        "        gray_img_scaled_tensor = transform(gray_image)\n",
        "\n",
        "        gray_tensor_scaled_squeezed = gray_img_scaled_tensor.squeeze(0)\n",
        "        gray_scaled_arr = gray_tensor_scaled_squeezed.numpy()\n",
        "\n",
        "        # plt.imshow(gray_scaled_arr, cmap='gray')\n",
        "        # plt.title('gray_scaled_arr')\n",
        "        # plt.show()\n",
        "\n",
        "        tile_size = 128\n",
        "        tiles = gray_tensor.unfold(1, tile_size, tile_size).unfold(2, tile_size, tile_size)\n",
        "        tiles = tiles.contiguous().view(-1, tile_size, tile_size)\n",
        "\n",
        "        for tile_index, tile in enumerate(tiles):\n",
        "          tile = tile / tile.max()\n",
        "          save_image(tile, f'/content/drive/MyDrive/automap/img_tiles/file_{file_index}_tile_{tile_index}.png')\n",
        "\n",
        "\n",
        "        resized_image = transform(gray_image)\n",
        "        resized_images.append(resized_image)\n",
        "\n",
        "\n",
        "    return torch.stack(resized_images)\n",
        "\n",
        "# Example usage\n",
        "image_paths = file_paths\n",
        "output_size = (256, 256)\n",
        "resized_batch = resize_images(image_paths, output_size)"
      ],
      "metadata": {
        "id": "DgylUdmocSvK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_paths)"
      ],
      "metadata": {
        "id": "-5w1qBf-QB8p",
        "outputId": "cd621c87-01a8-4c7c-9289-81ecc36a693d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/automap/imgs/10155709300728342918543955138521808206_f7cj92.png', '/content/drive/MyDrive/automap/imgs/10383960670432673238945376919735423432_hd3moq.png', '/content/drive/MyDrive/automap/imgs/1256842362861431725328351539259305635_u1qifz.png', '/content/drive/MyDrive/automap/imgs/10287653421930576798556842610982533460_vpbhw6.png', '/content/drive/MyDrive/automap/imgs/17517381147706809156163698942582418325_tutfbr.png', '/content/drive/MyDrive/automap/imgs/23519598294167460669966745319398153772_4fvhwr.png', '/content/drive/MyDrive/automap/imgs/17871983995291973291210205507121602296_hd8ger.png', '/content/drive/MyDrive/automap/imgs/18104280246346700713752899198427570737_ezdqyq.png', '/content/drive/MyDrive/automap/imgs/24716339483627393401392199056832608433_wtt5qq.png', '/content/drive/MyDrive/automap/imgs/10996416492353037588312781035930080694_8rstz0.png', '/content/drive/MyDrive/automap/imgs/26740916849083948015827135783885268528-2_6hkbx5.png', '/content/drive/MyDrive/automap/imgs/15606713623657301981614912219511809416_2_94v295.png', '/content/drive/MyDrive/automap/imgs/13353724432735380699905228693882625716_1tbyf9.png', '/content/drive/MyDrive/automap/imgs/16061525395627866800451108188666498463_f9mrv9.png', '/content/drive/MyDrive/automap/imgs/26740916849083948015827135783885268528_e8uwfn.png', '/content/drive/MyDrive/automap/imgs/62251368659414281768550499840080640229_8jw2hb.png', '/content/drive/MyDrive/automap/imgs/49538570955854652971715060419437210854_qfxazj.png', '/content/drive/MyDrive/automap/imgs/28679939396004151795585406073042323038_psrr3m.png', '/content/drive/MyDrive/automap/imgs/62440969118040059965044820734401488887_6hzwt0.png', '/content/drive/MyDrive/automap/imgs/47557396307760215809300057577936592627_m7mq32.png', '/content/drive/MyDrive/automap/imgs/47513502650936350354964244779459913004-3_th1gik.png', '/content/drive/MyDrive/automap/imgs/62774794894109549387630855543283311955_2_tdirok.png', '/content/drive/MyDrive/automap/imgs/33669092406557001556710892720325153219_eq21sh.png', '/content/drive/MyDrive/automap/imgs/33728467384543072824771678110722875201_f9qa0p.png', '/content/drive/MyDrive/automap/imgs/30661727075761817007267292459310975718_86nsuj.png', '/content/drive/MyDrive/automap/imgs/103416378058309979932405295235813040436_1g2pmw.png', '/content/drive/MyDrive/automap/imgs/91815015110608941073755910413288028905_kwjolc.png', '/content/drive/MyDrive/automap/imgs/100469495785351489872749036114751610212_rfyvv7.png', '/content/drive/MyDrive/automap/imgs/87180314458623865269977662447356279507_tcw56c.png', '/content/drive/MyDrive/automap/imgs/97600927297254707513662656394991173027_0k06p2.png', '/content/drive/MyDrive/automap/imgs/89871789430838637694883774745784638013_y2t9e8.png', '/content/drive/MyDrive/automap/imgs/86236188012565981583483399251510590408_2_vw97dk.png', '/content/drive/MyDrive/automap/imgs/63510470621460583865307590457045621750_wfd1y4.png', '/content/drive/MyDrive/automap/imgs/64947154984935334365130497226051564059_piq56n.png', '/content/drive/MyDrive/automap/imgs/69949397621405752847745986326314413051_wai6lj.png', '/content/drive/MyDrive/automap/imgs/62774794894109549387630855543283311955_9jbiyo.png', '/content/drive/MyDrive/automap/imgs/84856267960116899671078402865134921840_j5zwtq.png', '/content/drive/MyDrive/automap/imgs/110057948387370363009458390264986734403_myst7q.png', '/content/drive/MyDrive/automap/imgs/112456448066531979951054695594530500685_wrc6wl.png', '/content/drive/MyDrive/automap/imgs/112178367511062740933520645402062866244_5sqjdi.png', '/content/drive/MyDrive/automap/imgs/111524717177122678951114473577277787051_kt9www.png', '/content/drive/MyDrive/automap/imgs/108757234707826731622534463166732014399_zneaoc.png', '/content/drive/MyDrive/automap/imgs/108392178527872886183110835574345380047_dc2agp.png', '/content/drive/MyDrive/automap/imgs/106111337169988693038323274011777746837_0yin7u.png', '/content/drive/MyDrive/automap/imgs/111018930978236771390670303639566239985_1bnarb.png', '/content/drive/MyDrive/automap/imgs/107826458213940261956471276912177567239_9467w9.png', '/content/drive/MyDrive/automap/imgs/111016754890854009969250427027267219881_wkp0ya.png', '/content/drive/MyDrive/automap/imgs/104055072637907464008767269203861924017_huh41k.png', '/content/drive/MyDrive/automap/imgs/127193766790524852458047964184829087241_klomkd.png', '/content/drive/MyDrive/automap/imgs/120641250378848817226599591125249193787_1vwu72.png', '/content/drive/MyDrive/automap/imgs/121369866312829737404259612004787672904_od40ao.png', '/content/drive/MyDrive/automap/imgs/114041240061582113028394479929792704149_u7xmxu.png', '/content/drive/MyDrive/automap/imgs/115733055953927986967208164376379449432_li9tme.png', '/content/drive/MyDrive/automap/imgs/117503487105610561494614672580071778723_egzn5w.png', '/content/drive/MyDrive/automap/imgs/126455653911678893263056441159987922516_uz7fwy.png', '/content/drive/MyDrive/automap/imgs/115252833781991791197512509423446047187_pnh4fu.png', '/content/drive/MyDrive/automap/imgs/121982858364557665434391755127892214185_1e27fz.png', '/content/drive/MyDrive/automap/imgs/127776313362848303557368271134995152837_apvrf1.png', '/content/drive/MyDrive/automap/imgs/117922406082772720514160287292487390144_3qnpe6.png', '/content/drive/MyDrive/automap/imgs/119688533980562249677219589534851011987_60uvre.png', '/content/drive/MyDrive/automap/imgs/131603548504748381186066883008735293279_x4x4ls.png', '/content/drive/MyDrive/automap/imgs/134230638227943448483430779879455672678_nkryka.png', '/content/drive/MyDrive/automap/imgs/131241147536242919540082434604973143614_3wsmbz.png', '/content/drive/MyDrive/automap/imgs/137978876620819180655083942883406964928_so8cty.png', '/content/drive/MyDrive/automap/imgs/131648682133615188228601432675633412320_yw4cvh.png', '/content/drive/MyDrive/automap/imgs/145427013841140062478220774079107134701-2_yq5war.png', '/content/drive/MyDrive/automap/imgs/137967645291829623589025104429037566245_ty0ua4.png', '/content/drive/MyDrive/automap/imgs/133117830164386750221716087231377502440_w4gp1z.png', '/content/drive/MyDrive/automap/imgs/129242675756041973355687068645321283308_ufajm6.png', '/content/drive/MyDrive/automap/imgs/137388819814035428537164273550346941304_uaixht.png', '/content/drive/MyDrive/automap/imgs/153727633750702336351810492317390365896_iycqix.png', '/content/drive/MyDrive/automap/imgs/146381384591357414868726401545939282660_96eirs.png', '/content/drive/MyDrive/automap/imgs/145698282304700116300882843111967537977_f6qhtv.png', '/content/drive/MyDrive/automap/imgs/145769364607358984473800346357899635518_w3mh7f.png', '/content/drive/MyDrive/automap/imgs/155691603412384342537901614325751648892_2x8184.png', '/content/drive/MyDrive/automap/imgs/147856697855406216911500275209241729282_u5p8bx.png', '/content/drive/MyDrive/automap/imgs/147036015370488755117195440122198442935_gj6nyv.png', '/content/drive/MyDrive/automap/imgs/150925806630506707155140197611651038951_506rh8.png', '/content/drive/MyDrive/automap/imgs/145987248740080156691960355717233717054_fbjstn.png', '/content/drive/MyDrive/automap/imgs/152733907856972127971985724804321889809_u7ghw8.png', '/content/drive/MyDrive/automap/imgs/175993948212683701562003497511214331387_sr16co.png', '/content/drive/MyDrive/automap/imgs/157943178667978315593423977854134065828_w1j177.png', '/content/drive/MyDrive/automap/imgs/159216970546428043543933950339353602394_t0rgza.png', '/content/drive/MyDrive/automap/imgs/162648608648453851477134030640090786312_97dr7j.png', '/content/drive/MyDrive/automap/imgs/167426234824700370197428233814927580454_mgkykn.png', '/content/drive/MyDrive/automap/imgs/173480850478104643017119358503404014196_qey2vk.png', '/content/drive/MyDrive/automap/imgs/163458460465612645961271966254638198735_8tlhrq.png', '/content/drive/MyDrive/automap/imgs/174600210814713315828954104869955154340_y7nqyx.png', '/content/drive/MyDrive/automap/imgs/159364525876157332485573893353941089455_aepmh7.png', '/content/drive/MyDrive/automap/imgs/160327085026839567388469656243162554002_4rz0zs.png', '/content/drive/MyDrive/automap/imgs/174670802714657222439280962872741263127_7fupbg.png', '/content/drive/MyDrive/automap/imgs/182153357033863986819477081579951131676_yetgon.png', '/content/drive/MyDrive/automap/imgs/177242461410205305911459438621785113319_wxnhs2.png', '/content/drive/MyDrive/automap/imgs/176139149165255627395732438927565115933_2_cvhkvs.png', '/content/drive/MyDrive/automap/imgs/199072368172967010909636348828886390156_co5vik.png', '/content/drive/MyDrive/automap/imgs/220991425902150564296792633654689602163_hrvmt4.png', '/content/drive/MyDrive/automap/imgs/208665949772531573966572593951616806531_n8qw25.png', '/content/drive/MyDrive/automap/imgs/221516731243657777508708160092801128398_d8pxyz.png', '/content/drive/MyDrive/automap/imgs/185103609082807172741758831509642702963_w5om81.png', '/content/drive/MyDrive/automap/imgs/204422322492048939194499080859737112307_pjmtqu.png', '/content/drive/MyDrive/automap/imgs/207601568257371629456571671613073108105_rd3vig.png', '/content/drive/MyDrive/automap/imgs/186710864282628233004220911541749949393_sb4ype.png', '/content/drive/MyDrive/automap/imgs/245895219126534788779109786698958326807_1a9ait.png', '/content/drive/MyDrive/automap/imgs/229647061532869405127486256298724729451_o2d0lv.png', '/content/drive/MyDrive/automap/imgs/255685135940885410514594136492164638096_m86wzw.png', '/content/drive/MyDrive/automap/imgs/232572031807344965043258496995347066691_g4zxoq.png', '/content/drive/MyDrive/automap/imgs/224904318374059042978778904037988750967_dbs3bj.png', '/content/drive/MyDrive/automap/imgs/251817752826726742233508350809968475767_o1z8dd.png', '/content/drive/MyDrive/automap/imgs/234342142542575223651664904935164209557_57uem0.png', '/content/drive/MyDrive/automap/imgs/235853514537661378209836459660303802572_-bl64a.png', '/content/drive/MyDrive/automap/imgs/241628199575537995884366376583690323975_tgclgn.png', '/content/drive/MyDrive/automap/imgs/228505125625411655559042398552685461655_cvearx.png', '/content/drive/MyDrive/automap/imgs/239328921181741075231340728462151367739_z8w503.png', '/content/drive/MyDrive/automap/imgs/242212504721475153281566846983009162353_1v0l8r.png', '/content/drive/MyDrive/automap/imgs/242159935290547449788910895844948743899_pxrrfs.png', '/content/drive/MyDrive/automap/imgs/278781644981372306896738110447513784487_2z4xsa.png', '/content/drive/MyDrive/automap/imgs/287674558154154196238750035876376456720_de0kdu.png', '/content/drive/MyDrive/automap/imgs/257475948814337233640540177569885227207_jaj8iw.png', '/content/drive/MyDrive/automap/imgs/284353054075043225622260270287627142906_kduagg.png', '/content/drive/MyDrive/automap/imgs/287658295007948631772703202498743716060_3yiz93.png', '/content/drive/MyDrive/automap/imgs/289108620230468119174968226927683707287_9wupg2.png', '/content/drive/MyDrive/automap/imgs/278147989796380509519073707235611243961_lgo9hx.png', '/content/drive/MyDrive/automap/imgs/282084762366059076387208905274707563447_d4ptrb.png', '/content/drive/MyDrive/automap/imgs/269577503052282080020245006456074886585_yqub0o.png', '/content/drive/MyDrive/automap/imgs/266463130540256183061556297994476560538_jkbs4h.png', '/content/drive/MyDrive/automap/imgs/313697209576187055457395864503092360851_8joobi.png', '/content/drive/MyDrive/automap/imgs/307400577352691476839033094654629005292_2_eyg2tu.png', '/content/drive/MyDrive/automap/imgs/316310243794898186923644098315438248232_5jyw88.png', '/content/drive/MyDrive/automap/imgs/309362609894399458585188858667076734340_312chn.png', '/content/drive/MyDrive/automap/imgs/325164322016612295040208415099913503835_djqek1.png', '/content/drive/MyDrive/automap/imgs/292918128360817403765919130571877152208_3ibhhb.png', '/content/drive/MyDrive/automap/imgs/293237814606131965920904052737398761929_wo83it.png', '/content/drive/MyDrive/automap/imgs/296076958641695785561110249259065599111_tfzq7g.png', '/content/drive/MyDrive/automap/imgs/306454472377761167397878598740821355166_kvraex.png', '/content/drive/MyDrive/automap/imgs/304673909503207424801802419702123736315_vyckk1.png', '/content/drive/MyDrive/automap/imgs/335389077904052440696851091734860414013_2ukkfm.png', '/content/drive/MyDrive/automap/imgs/327043651451092435505761971551575640871_3qwimg.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow code"
      ],
      "metadata": {
        "id": "PPcxb7io9GsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_x(y, normalize=False):\n",
        "    \"\"\"\n",
        "    Prepares frequency data from image data: applies to_freq_space,\n",
        "    expands the dimensions from 3D to 4D, and normalizes if normalize=True\n",
        "    :param y: input image\n",
        "    :param normalize: if True - the frequency data will be normalized\n",
        "    :return: frequency data 4D array of size (1, im_size1, im_size2, 2)\n",
        "    \"\"\"\n",
        "    x = to_freq_space(y)  # FFT: (128, 128, 2)\n",
        "    x = np.expand_dims(x, axis=0)  # (1, 128, 128, 2)\n",
        "    if normalize:\n",
        "        x = x - np.mean(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def to_freq_space(img):\n",
        "    \"\"\" Performs FFT of an image\n",
        "    :param img: input 2D image\n",
        "    :return: Frequency-space data of the input image, third dimension (size: 2)\n",
        "    contains real ans imaginary part\n",
        "    \"\"\"\n",
        "\n",
        "    img_f = np.fft.fft2(img)  # FFT\n",
        "    img_fshift = np.fft.fftshift(img_f)  # FFT shift\n",
        "    img_real = img_fshift.real  # Real part: (im_size1, im_size2)\n",
        "    img_imag = img_fshift.imag  # Imaginary part: (im_size1, im_size2)\n",
        "    img_real_imag = np.dstack((img_real, img_imag))  # (im_size1, im_size2, 2)\n",
        "\n",
        "    return img_real_imag\n",
        "\n",
        "\n",
        "\n",
        "def load_x_ray_data(train_imgs_dir, img_file_start, img_file_stop):\n",
        "  # Get a list of all the image file paths\n",
        "  file_paths = glob.glob(f'{train_imgs_dir}/*.png')\n",
        "  file_paths = file_paths[img_file_start:img_file_stop]\n",
        "\n",
        "  # Create a dataset of the file paths\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
        "\n",
        "  # Function to load and preprocess each image\n",
        "  def load_and_preprocess_image(path):\n",
        "      # Read the image from disk\n",
        "      image = tf.io.read_file(path)\n",
        "\n",
        "      # Decode the image\n",
        "      image = tf.image.decode_image(image, channels=1)\n",
        "\n",
        "      # Convert the image to float values between 0 and 1\n",
        "      image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "      return image\n",
        "\n",
        "  # Apply the function to each image in the dataset\n",
        "  dataset = dataset.map(load_and_preprocess_image)\n",
        "\n",
        "  # Convert the dataset to a single tensor\n",
        "  images = tf.stack(list(dataset))\n",
        "\n",
        "  bigy = images.numpy()\n",
        "  bigy = np.squeeze(bigy)\n",
        "\n",
        "  print(f'bigy.shape = {bigy.shape}')\n",
        "\n",
        "  # convert to k-space\n",
        "  imgs, row, col = bigy.shape\n",
        "  bigx = np.empty((imgs, row, col, 2))\n",
        "  for i in range(imgs):\n",
        "      bigx[i, :, :, :] = create_x(np.squeeze(bigy[i,:,:]), normalize=False)\n",
        "\n",
        "      # print(f'processing image {i}/{range(imgs)}')\n",
        "\n",
        "  # convert bigx from complex to abs values\n",
        "  bigy = np.abs(bigy)\n",
        "\n",
        "  return bigx, bigy\n"
      ],
      "metadata": {
        "id": "d1QarrQIiWeW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_train = '/content/drive/MyDrive/automap/img_tiles'\n",
        "X_train, Y_train = load_x_ray_data(dir_train, 0, 1000)\n",
        "print(f'x train shape = {X_train.shape}, y train shape = {Y_train.shape}')\n"
      ],
      "metadata": {
        "id": "Gqt9KcQddx5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdee79f2-e8f9-4454-806b-b0bb5ef14179"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigy.shape = (548, 128, 128)\n",
            "x train shape = (548, 128, 128, 2), y train shape = (548, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq5KJsbF_Ap7",
        "outputId": "0a042380-1fda-4f83-d8e8-7351cbcbf29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(548, 128, 128, 2)\n",
            "(548, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AUTOMAP(Model):\n",
        "    def __init__(self, n_H0, n_W0):\n",
        "        super(AUTOMAP, self).__init__()\n",
        "\n",
        "        print(f'n_H0 = {n_H0}, n_W0 = {n_W0}')\n",
        "\n",
        "        # Compute the output shape\n",
        "        self.n_out = n_H0 * n_W0\n",
        "\n",
        "        # Define layers\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(self.n_out, activation='tanh', kernel_initializer='glorot_uniform')\n",
        "        self.fc2 = Dense(self.n_out, activation='tanh', kernel_initializer='glorot_uniform')\n",
        "        self.reshape = Reshape((n_H0, n_W0, 1))\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = Conv2D(64, kernel_size=5, padding='same', activation='relu', kernel_initializer='glorot_uniform')\n",
        "        self.conv2 = Conv2D(64, kernel_size=5, padding='same', activation='relu', kernel_initializer='glorot_uniform')\n",
        "\n",
        "        # Deconvolutional layer\n",
        "        self.deconv = Conv2D(1, kernel_size=7, padding='same', activation='relu', kernel_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x):\n",
        "        print(f'x shape 1 = {x.shape}')\n",
        "        x = self.flatten(x)\n",
        "        print(f'x shape 2 = {x.shape}')\n",
        "        x = self.fc1(x)\n",
        "        print(f'x shape 2.1 = {x.shape}')\n",
        "        x = self.fc2(x)\n",
        "        print(f'x shape 2.2 = {x.shape}')\n",
        "        x = self.reshape(x)\n",
        "        print(f'x shape 3 = {x.shape}')\n",
        "        x = self.conv1(x)\n",
        "        print(f'x shape 4 = {x.shape}')\n",
        "        x = self.conv2(x)\n",
        "        print(f'x shape 5 = {x.shape}')\n",
        "        x = self.deconv(x)\n",
        "        print(f'x shape 6 = {x.shape}')\n",
        "        return x\n",
        "\n",
        "def compute_cost(y_pred, y_true):\n",
        "    \"\"\"Computes cost (squared loss) between the prediction and the label image\"\"\"\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "def train_model(X_train, Y_train, learning_rate=0.0001, num_epochs=100, minibatch_size=5):\n",
        "    \"\"\"Trains the model\"\"\"\n",
        "    model = AUTOMAP(n_H0=X_train.shape[1], n_W0=X_train.shape[2])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate, rho=0.9)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        aligned_batch_size = (X_train.shape[0] // minibatch_size) * minibatch_size\n",
        "        print(f'aligned_batch_size = {aligned_batch_size}')\n",
        "        for i in range(0, aligned_batch_size, minibatch_size):\n",
        "            x_batch = X_train[i:i+minibatch_size]\n",
        "            y_batch = Y_train[i:i+minibatch_size]\n",
        "\n",
        "            x_batch = tf.convert_to_tensor(x_batch)\n",
        "            y_batch = tf.convert_to_tensor(y_batch)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pred = model(x_batch)\n",
        "                # print(f'y_pred.shape={y_pred.shape}')\n",
        "                # print(f'y_batch.shape={y_batch.shape}')\n",
        "\n",
        "                # print(f'y_pred type = {y_pred.dtype}')\n",
        "                # print(f'y_batch tppe = {y_batch.dtype}')\n",
        "\n",
        "                y_pred = tf.squeeze(y_pred)\n",
        "                # print(f'y_pred type = {y_pred.dtype}')\n",
        "\n",
        "                loss = compute_cost(y_pred, y_batch)\n",
        "\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch: {epoch}, Iteration: {i}, Loss: {loss}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "wqWlYthWHFy4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train.astype(np.float32)\n",
        "Y = Y_train\n",
        "print(f'X type={X.dtype}')\n",
        "print(f'Y type={Y.dtype}')\n",
        "print(f'X shape = {X.shape}')\n",
        "print(f'Y shape = {Y.shape}')\n"
      ],
      "metadata": {
        "id": "GbjqEpZQH9x1",
        "outputId": "665d7fe0-4c36-4549-d548-5e47cf4d8c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X type=float32\n",
            "Y type=float32\n",
            "X shape = (548, 128, 128, 2)\n",
            "Y shape = (548, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(X_train=X, Y_train=Y, num_epochs=20)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wT9K33sXzIYw",
        "outputId": "ad52d33e-41ae-4c99-fba4-9469d93313bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_H0 = 128, n_W0 = 128\n",
            "aligned_batch_size = 545\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x78bc06110a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x78bc06110a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iteration: 0, Loss: 0.3857605457305908\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "Epoch: 0, Iteration: 100, Loss: 0.05397961288690567\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n",
            "x shape 1 = (5, 128, 128, 2)\n",
            "x shape 2 = (5, 32768)\n",
            "x shape 2.1 = (5, 16384)\n",
            "x shape 2.2 = (5, 16384)\n",
            "x shape 3 = (5, 128, 128, 1)\n",
            "x shape 4 = (5, 128, 128, 64)\n",
            "x shape 5 = (5, 128, 128, 64)\n",
            "x shape 6 = (5, 128, 128, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8480ca8bce79>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-5fcef2470797>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, Y_train, learning_rate, num_epochs, minibatch_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m   \"\"\"\n\u001b[0;32m-> 1496\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1497\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1503\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m   \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    269\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    278\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())\n",
        "model.save('/content/drive/MyDrive/automap/automap_model_2')"
      ],
      "metadata": {
        "id": "7C4CwRpd-iyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = model\n",
        "print(trained_model.summary())"
      ],
      "metadata": {
        "id": "_4dRuowtzuCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare test data\n",
        "img_start = 201\n",
        "img_stop = 205\n",
        "# X_dev, Y_dev = load_STONE_data(  # Load images for training\n",
        "#     dir_train,\n",
        "#     n_cases,\n",
        "#     normalize=False,\n",
        "#     imrotate=False)\n",
        "\n",
        "dir_train = '/content/drive/MyDrive/automap/img_tiles'\n",
        "X_dev, Y_dev = load_x_ray_data(dir_train, img_start, img_stop)\n",
        "print('X_dev.shape at input = ', X_dev.shape)\n",
        "print('Y_dev.shape at input = ', Y_dev.shape)\n",
        "\n",
        "# Make sure to compile your model before using it\n",
        "trained_model.compile(optimizer='adam', loss='mse') # choose appropriate optimizer and loss for your problem\n",
        "\n",
        "Y_recon = trained_model.predict(X_dev)\n",
        "print('Y_recon.shape = ', Y_recon.shape)\n",
        "print('Y_dev.shape = ', Y_dev.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB8ckpioZqz0",
        "outputId": "797b6151-8308-4cde-cefb-bfef81f021c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigy.shape = (4, 128, 128)\n",
            "X_dev.shape at input =  (4, 128, 128, 2)\n",
            "Y_dev.shape at input =  (4, 128, 128)\n",
            "x shape 1 = (None, 128, 128, 2)\n",
            "x shape 2 = (None, 32768)\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Y_recon.shape =  (4, 128, 128, 1)\n",
            "Y_dev.shape =  (4, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other part of your code remains the same ...\n",
        "# Visualize the images, their reconstruction using iFFT and using trained model\n",
        "# 4 images to visualize:\n",
        "im1 = 0\n",
        "im2 = 1\n",
        "im3 = 2\n",
        "im4 = 3\n",
        "\n",
        "# iFFT back to image from corrupted frequency space\n",
        "# Complex image from real and imaginary part\n",
        "X_dev_compl = X_dev[:, :, :, 0] + X_dev[:, :, :, 1] * 1j\n",
        "\n",
        "#iFFT\n",
        "X_iFFT0 = np.fft.ifft2(X_dev_compl[im1, :, :])\n",
        "X_iFFT1 = np.fft.ifft2(X_dev_compl[im2, :, :])\n",
        "X_iFFT2 = np.fft.ifft2(X_dev_compl[im3, :, :])\n",
        "X_iFFT3 = np.fft.ifft2(X_dev_compl[im4, :, :])\n",
        "\n",
        "# Magnitude of complex image\n",
        "X_iFFT_M1 = np.sqrt(np.power(X_iFFT0.real, 2)\n",
        "                    + np.power(X_iFFT0.imag, 2))\n",
        "X_iFFT_M2 = np.sqrt(np.power(X_iFFT1.real, 2)\n",
        "                    + np.power(X_iFFT1.imag, 2))\n",
        "X_iFFT_M3 = np.sqrt(np.power(X_iFFT2.real, 2)\n",
        "                    + np.power(X_iFFT2.imag, 2))\n",
        "X_iFFT_M4 = np.sqrt(np.power(X_iFFT3.real, 2)\n",
        "                    + np.power(X_iFFT3.imag, 2))\n",
        "\n",
        "# Display results\n",
        "# Show X - input k-space\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.subplot(441), plt.imshow(np.abs(X_dev_compl[im1, :, :]), cmap='gray')\n",
        "plt.title('InputX-im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(442), plt.imshow(np.abs(X_dev_compl[im2, :, :]), cmap='gray')\n",
        "plt.title('InputX-im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(443), plt.imshow(np.abs(X_dev_compl[im3, :, :]), cmap='gray')\n",
        "plt.title('InputX-im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(444), plt.imshow(np.abs(X_dev_compl[im4, :, :]), cmap='gray')\n",
        "plt.title('InputX-im4'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# Show Y - ground truth\n",
        "plt.subplot(445), plt.imshow(Y_dev[im1, :, :], cmap='gray')\n",
        "plt.title('InputY-im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(446), plt.imshow(Y_dev[im2, :, :], cmap='gray')\n",
        "plt.title('InputY-im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(447), plt.imshow(Y_dev[im3, :, :], cmap='gray')\n",
        "plt.title('InputY-im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(448), plt.imshow(Y_dev[im4, :, :], cmap='gray')\n",
        "plt.title('InputY-im4'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# Show images reconstructed using iFFT\n",
        "plt.subplot(449), plt.imshow(X_iFFT_M1, cmap='gray')\n",
        "plt.title('iFFT_X_im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,10), plt.imshow(X_iFFT_M2, cmap='gray')\n",
        "plt.title('iFFT_X_im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,11), plt.imshow(X_iFFT_M3, cmap='gray')\n",
        "plt.title('iFFT_X_im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,12), plt.imshow(X_iFFT_M4, cmap='gray')\n",
        "plt.title('iFFT_X_im4'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# Show images reconstructed using neural network\n",
        "plt.subplot(4,4,13), plt.imshow(Y_recon[im1, :, :], cmap='gray')\n",
        "plt.title('Output-im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,14), plt.imshow(Y_recon[im2, :, :], cmap='gray')\n",
        "plt.title('Output-im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,15), plt.imshow(Y_recon[im3, :, :], cmap='gray')\n",
        "plt.title('Output-im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,16), plt.imshow(Y_recon[im4, :, :], cmap='gray')\n",
        "plt.title('Output-im4'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplots_adjust(hspace=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zYZCoC5reyX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the images, their reconstruction using iFFT and using trained model\n",
        "# 4 images to visualize:\n",
        "im1 = 15\n",
        "im2 = 16\n",
        "im3 = 17\n",
        "im4 = 18\n",
        "\n",
        "# iFFT back to image from corrupted frequency space\n",
        "# Complex image from real and imaginary part\n",
        "X_dev_compl = X_dev[:, :, :, 0] + X_dev[:, :, :, 1] * 1j\n",
        "\n",
        "#iFFT\n",
        "X_iFFT0 = np.fft.ifft2(X_dev_compl[im1, :, :])\n",
        "X_iFFT1 = np.fft.ifft2(X_dev_compl[im2, :, :])\n",
        "X_iFFT2 = np.fft.ifft2(X_dev_compl[im3, :, :])\n",
        "X_iFFT3 = np.fft.ifft2(X_dev_compl[im4, :, :])\n",
        "\n",
        "# Magnitude of complex image\n",
        "X_iFFT_M1 = np.sqrt(np.power(X_iFFT0.real, 2)\n",
        "                    + np.power(X_iFFT0.imag, 2))\n",
        "X_iFFT_M2 = np.sqrt(np.power(X_iFFT1.real, 2)\n",
        "                    + np.power(X_iFFT1.imag, 2))\n",
        "X_iFFT_M3 = np.sqrt(np.power(X_iFFT2.real, 2)\n",
        "                    + np.power(X_iFFT2.imag, 2))\n",
        "X_iFFT_M4 = np.sqrt(np.power(X_iFFT3.real, 2)\n",
        "                    + np.power(X_iFFT3.imag, 2))\n",
        "\n",
        "# Display results\n",
        "# Show X - input k-space\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.subplot(441), plt.imshow(np.abs(X_dev_compl[im1, :, :]), cmap='gray')\n",
        "plt.title('InputX-im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(442), plt.imshow(np.abs(X_dev_compl[im2, :, :]), cmap='gray')\n",
        "plt.title('InputX-im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(443), plt.imshow(np.abs(X_dev_compl[im3, :, :]), cmap='gray')\n",
        "plt.title('InputX-im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(444), plt.imshow(np.abs(X_dev_compl[im4, :, :]), cmap='gray')\n",
        "plt.title('InputX-im4'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# Show Y - ground truth\n",
        "plt.subplot(445), plt.imshow(Y_dev[im1, :, :], cmap='gray')\n",
        "plt.title('InputY-im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(446), plt.imshow(Y_dev[im2, :, :], cmap='gray')\n",
        "plt.title('InputY-im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(447), plt.imshow(Y_dev[im3, :, :], cmap='gray')\n",
        "plt.title('InputY-im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(448), plt.imshow(Y_dev[im4, :, :], cmap='gray')\n",
        "plt.title('InputY-im4'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# Show images reconstructed using iFFT\n",
        "plt.subplot(449), plt.imshow(X_iFFT_M1, cmap='gray')\n",
        "plt.title('iFFT_X_im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,10), plt.imshow(X_iFFT_M2, cmap='gray')\n",
        "plt.title('iFFT_X_im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,11), plt.imshow(X_iFFT_M3, cmap='gray')\n",
        "plt.title('iFFT_X_im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,12), plt.imshow(X_iFFT_M4, cmap='gray')\n",
        "plt.title('iFFT_X_im4'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# Show images reconstructed using neural network\n",
        "plt.subplot(4,4,13), plt.imshow(Y_recon[im1, :, :], cmap='gray')\n",
        "plt.title('Output-im1'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,14), plt.imshow(Y_recon[im2, :, :], cmap='gray')\n",
        "plt.title('Output-im2'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,15), plt.imshow(Y_recon[im3, :, :], cmap='gray')\n",
        "plt.title('Output-im3'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(4,4,16), plt.imshow(Y_recon[im4, :, :], cmap='gray')\n",
        "plt.title('Output-im4'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplots_adjust(hspace=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XOeuf0kfeift",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "5a32a9d5-c03a-40ce-a737-5614c6283f30"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-824a2e5569d5>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#iFFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX_iFFT0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_compl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mX_iFFT1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_compl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX_iFFT2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_compl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch code\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jn6yADC8FXSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_x(y, normalize=False):\n",
        "    \"\"\"\n",
        "    Prepares frequency data from image data: applies to_freq_space,\n",
        "    expands the dimensions from 3D to 4D, and normalizes if normalize=True\n",
        "    :param y: input image\n",
        "    :param normalize: if True - the frequency data will be normalized\n",
        "    :return: frequency data 4D array of size (1, im_size1, im_size2, 2)\n",
        "    \"\"\"\n",
        "    x = to_freq_space(y)  # FFT: (128, 128, 2)\n",
        "    x = np.expand_dims(x, axis=0)  # (1, 128, 128, 2)\n",
        "    if normalize:\n",
        "        x = x - np.mean(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def to_freq_space(img):\n",
        "    \"\"\" Performs FFT of an image\n",
        "    :param img: input 2D image\n",
        "    :return: Frequency-space data of the input image, third dimension (size: 2)\n",
        "    contains real ans imaginary part\n",
        "    \"\"\"\n",
        "\n",
        "    img_f = np.fft.fft2(img)  # FFT\n",
        "    img_fshift = np.fft.fftshift(img_f)  # FFT shift\n",
        "    img_real = img_fshift.real  # Real part: (im_size1, im_size2)\n",
        "    img_imag = img_fshift.imag  # Imaginary part: (im_size1, im_size2)\n",
        "    img_real_imag = np.dstack((img_real, img_imag))  # (im_size1, im_size2, 2)\n",
        "\n",
        "    return img_real_imag\n",
        "\n",
        "\n",
        "\n",
        "def load_x_ray_data(train_imgs_dir, img_file_start, img_file_stop):\n",
        "  # Get a list of all the image file paths\n",
        "  file_paths = glob.glob(f'{train_imgs_dir}/*.png')\n",
        "  file_paths = file_paths[img_file_start:img_file_stop]\n",
        "\n",
        "  # Create a dataset of the file paths\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
        "\n",
        "  # Function to load and preprocess each image\n",
        "  def load_and_preprocess_image(path):\n",
        "      # Read the image from disk\n",
        "      image = tf.io.read_file(path)\n",
        "\n",
        "      # Decode the image\n",
        "      image = tf.image.decode_image(image, channels=1)\n",
        "\n",
        "      # Convert the image to float values between 0 and 1\n",
        "      image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "      return image\n",
        "\n",
        "  # Apply the function to each image in the dataset\n",
        "  dataset = dataset.map(load_and_preprocess_image)\n",
        "\n",
        "  # Convert the dataset to a single tensor\n",
        "  images = tf.stack(list(dataset))\n",
        "\n",
        "  bigy = images.numpy()\n",
        "  bigy = np.squeeze(bigy)\n",
        "\n",
        "  print(f'bigy.shape = {bigy.shape}')\n",
        "\n",
        "  # convert to k-space\n",
        "  imgs, row, col = bigy.shape\n",
        "  bigx = np.empty((imgs, row, col, 2))\n",
        "  for i in range(imgs):\n",
        "      bigx[i, :, :, :] = create_x(np.squeeze(bigy[i,:,:]), normalize=False)\n",
        "\n",
        "      # print(f'processing image {i}/{range(imgs)}')\n",
        "\n",
        "  # convert bigx from complex to abs values\n",
        "  bigy = np.abs(bigy)\n",
        "\n",
        "  return bigx, bigy"
      ],
      "metadata": {
        "id": "1hqv2_Wz1YX_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torchvision.transforms import functional as F\n",
        "# from torchvision.transforms import RandomCrop\n",
        "# import PIL.Image as Image\n",
        "# import numpy as np\n",
        "\n",
        "class SymmetricTiling:\n",
        "    def __init__(self, size=128, num_crops=10):\n",
        "        self.size = size\n",
        "        self.random_crop = RandomCrop(size)\n",
        "        self.num_crops = num_crops\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Symmetrically tile the image\n",
        "        top_bottom_flip = F.hflip(img)\n",
        "        tiled_img = torch.cat((img, top_bottom_flip), dim=1)\n",
        "        left_right_flip = F.vflip(tiled_img)\n",
        "        tiled_img = torch.cat((tiled_img, left_right_flip), dim=2)\n",
        "\n",
        "        # Random 128x128 cropping 10 times\n",
        "        crops = []\n",
        "        for _ in range(self.num_crops):\n",
        "            crops.append(self.random_crop(tiled_img))\n",
        "\n",
        "        return crops\n",
        "\n",
        "# Assuming you're working with PIL Image, if not convert your image to PIL Image\n",
        "img_path = \"/content/drive/MyDrive/automap/img_tiles/file_0_tile_0.png\"\n",
        "img = Image.open(img_path)\n",
        "\n",
        "\n",
        "# Convert PIL Image to tensor\n",
        "img_tensor = F.to_tensor(img)\n",
        "\n",
        "# Create the augmentor and apply\n",
        "augmentor = SymmetricTiling()\n",
        "augmented_tensors = augmentor(img_tensor)\n",
        "\n",
        "for augmented_tensor in augmented_tensors:\n",
        "  # Convert tensor back to PIL Image for visualization (if needed)\n",
        "  augmented_img = F.to_pil_image(augmented_tensor)\n",
        "\n",
        "  plt.imshow(augmented_img)\n",
        "  plt.axis('off')  # Turn off the axis numbers\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "5ZTMEe2TP_ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_dir = '/content/drive/MyDrive/automap/img_tiles'\n",
        "\n",
        "def to_normalized_grayscale(tensor):\n",
        "    # Convert tensor to grayscale by averaging the channels\n",
        "    grayscale_tensor = tensor.mean(dim=0, keepdim=True)\n",
        "\n",
        "    grayscale_tensor = grayscale_tensor.squeeze()\n",
        "\n",
        "    # If the tensor values are between 0 and 255, divide by 255 to normalize\n",
        "    if grayscale_tensor.max() > 1:\n",
        "        grayscale_tensor = grayscale_tensor / 255.0\n",
        "\n",
        "    # print(f'grayscale_tensor.shape = {grayscale_tensor.shape}')\n",
        "\n",
        "    return grayscale_tensor\n",
        "\n",
        "\n",
        "# Initialize the augmentor\n",
        "augmentor = SymmetricTiling()\n",
        "\n",
        "images = []\n",
        "# Read and augment images from the directory\n",
        "for img_name in os.listdir(input_img_dir):\n",
        "    if img_name.endswith(\".png\"):\n",
        "        img_path = os.path.join(input_img_dir, img_name)\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        # Convert PIL Image to tensor\n",
        "        img_tensor = F.to_tensor(img)\n",
        "\n",
        "        # Augment the image to get 10 random slices\n",
        "        augmented_tensors = augmentor(img_tensor)\n",
        "\n",
        "        # Apply the conversion to each tensor in augmented_tensors\n",
        "        augmented_tensors = [to_normalized_grayscale(t) for t in augmented_tensors]\n",
        "        augmented_tensors = torch.stack(augmented_tensors)\n",
        "        # print(f'augmented_tensors shape = {augmented_tensors.shape}')\n",
        "\n",
        "        images.append(augmented_tensors)\n",
        "\n",
        "\n",
        "        # for augmented_tensor in augmented_tensors:\n",
        "        #     # Convert tensor back to PIL Image\n",
        "        #     augmented_img = F.to_pil_image(augmented_tensor)\n",
        "\n",
        "        #     plt.imshow(augmented_img, cmap='gray')\n",
        "        #     plt.axis('off')  # Turn off the axis numbers\n",
        "        #     plt.show()\n",
        "\n",
        "images = torch.cat(images, dim=0)\n",
        "print(f'images shape ={images.shape}')\n",
        "bigy = images.numpy()\n",
        "bigy = np.squeeze(bigy)\n",
        "\n",
        "print(f'bigy.shape = {bigy.shape}')\n",
        "\n",
        "# convert to k-space\n",
        "imgs, row, col = bigy.shape\n",
        "bigx = np.empty((imgs, row, col, 2))\n",
        "for i in range(imgs):\n",
        "    bigx[i, :, :, :] = create_x(np.squeeze(bigy[i,:,:]), normalize=False)\n",
        "\n",
        "    # print(f'processing image {i}/{range(imgs)}')\n",
        "\n",
        "# convert bigx from complex to abs values\n",
        "bigy = np.abs(bigy)\n",
        "\n",
        "X_train = bigx\n",
        "Y_train = bigy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5s5M2M4pB6X",
        "outputId": "c2b00368-fcb2-4b5e-f141-33285407a2e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images shape =torch.Size([5480, 128, 128])\n",
            "bigy.shape = (5480, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the AUTOMAP model\n",
        "class AUTOMAP(nn.Module):\n",
        "    def __init__(self, n_H0, n_W0):\n",
        "        super(AUTOMAP, self).__init__()\n",
        "\n",
        "        self.n_H0 = n_H0\n",
        "        self.n_W0 = n_W0\n",
        "\n",
        "        # Compute the output shape\n",
        "        self.n_out = n_H0 * n_W0\n",
        "\n",
        "        # Define layers\n",
        "        self.fc1 = nn.Linear(n_H0 * n_W0 * 2, self.n_out)\n",
        "        self.fc2 = nn.Linear(self.n_out, self.n_out)\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
        "\n",
        "        # Deconvolutional layer\n",
        "        self.deconv = nn.Conv2d(64, 1, kernel_size=7, padding=3)\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f'type x 1 = {type(x)}')\n",
        "        print(f'x shape 1 = {x.shape}')\n",
        "        x = x.view(x.shape[0], -1)  # Flatten\n",
        "        print(f'type x 2 = {type(x)}')\n",
        "        print(f'x shape 2 = {x.shape}')\n",
        "        x = self.tanh(self.fc1(x))\n",
        "        x = self.tanh(self.fc2(x))\n",
        "        x = x.view(x.shape[0], 1, self.n_H0, self.n_W0)  # Reshape\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.deconv(x))\n",
        "        return x\n",
        "\n",
        "def compute_cost(y_pred, y_true):\n",
        "    \"\"\"Computes cost (squared loss) between the prediction and the label image\"\"\"\n",
        "    return torch.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "\n",
        "# Converting the data to PyTorch tensors might look something like:\n",
        "# X_train = torch.tensor(X_train_np, dtype=torch.float32)\n",
        "# Y_train = torch.tensor(Y_train_np, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "JemOPS2TBGwh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train, Y_train, learning_rate=0.0001, num_epochs=100, minibatch_size=5):\n",
        "    \"\"\"Trains the model\"\"\"\n",
        "    print(f'train model, X_train.shape={X_train.shape}')\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f'device = {device}')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'X_train.shape = {X_train.shape}')\n",
        "        print(f'X_train.shape[0] = {X_train.shape[0]}')\n",
        "        print(f'minibatch_size = {minibatch_size}')\n",
        "        print(f'minibatch_size = {minibatch_size}')\n",
        "        aligned_batch_count = (X_train.shape[0] // minibatch_size) * minibatch_size\n",
        "\n",
        "        for i in range(0, aligned_batch_count, minibatch_size):\n",
        "            x_batch_np = X_train[i:i+minibatch_size]\n",
        "            y_batch_np = Y_train[i:i+minibatch_size]\n",
        "\n",
        "            print(f'type(x_batch_np) 1 = {type(x_batch_np)}')\n",
        "\n",
        "            # Convert to PyTorch tensor and ensure correct dtype\n",
        "            x_batch = torch.tensor(x_batch_np, dtype=torch.float32).to(device)\n",
        "            y_batch = torch.tensor(y_batch_np, dtype=torch.float32).to(device)\n",
        "\n",
        "            x_batch_elem_size = x_batch.element_size()\n",
        "            x_batch_numel = x_batch.numel()\n",
        "            x_batch_mem_usage = x_batch_elem_size * x_batch_numel\n",
        "            y_batch_elem_size = y_batch.element_size()\n",
        "            y_batch_numel = y_batch.numel()\n",
        "            y_batch_mem_usage = y_batch_elem_size * y_batch_numel\n",
        "\n",
        "            print(f'x_batch_elem_size = {x_batch_elem_size}')\n",
        "            print(f'x_batch_numel = {x_batch_numel}')\n",
        "            print(f'x_batch_mem_usage = {x_batch_mem_usage}')\n",
        "            print(f'y_batch_elem_size = {y_batch_elem_size}')\n",
        "            print(f'y_batch_numel = {y_batch_numel}')\n",
        "            print(f'y_batch_mem_usage = {y_batch_mem_usage}')\n",
        "\n",
        "\n",
        "            print(f'type(x_batch) 2 = {type(x_batch)}')\n",
        "            print(f'x_batch shape = {x_batch.shape}')\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x_batch)\n",
        "            loss = compute_cost(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "oozHtE1deB_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'gpu memory_allocated = {torch.cuda.memory_allocated()}')  # Returns the current GPU memory usage by tensors in bytes\n",
        "print(f'gpu cuda memory reserved = {torch.cuda.memory_reserved()}')   # Returns the current GPU memory managed by the caching allocator in bytes\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(f'gpu memory_allocated = {torch.cuda.memory_allocated()}')  # Returns the current GPU memory usage by tensors in bytes\n",
        "print(f'gpu cuda memory reserved = {torch.cuda.memory_reserved()}')   # Returns the current GPU memory managed by the caching allocator in bytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZyaIu7PBuEj",
        "outputId": "cded81a1-3ce1-44e8-c5c8-3c251bbbf053"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu memory_allocated = 0\n",
            "gpu cuda memory reserved = 0\n",
            "gpu memory_allocated = 0\n",
            "gpu cuda memory reserved = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n"
      ],
      "metadata": {
        "id": "K1IK5RWfFgsq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zry9qIR2ZqZG",
        "outputId": "93e8e30a-68e4-4017-f308-631bb31967c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4299"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "metadata": {
        "id": "Z7FLuGiyVw5V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AUTOMAP(X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "print(f'Total trainable parameters [Mbyes]: {count_parameters(model) * 4 / 1e6}')\n",
        "\n",
        "print(model.to('cpu'))\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device = {device}')\n",
        "model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "gGjse0Bz7wks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train  = X_train.squeeze()\n",
        "Y_train = Y_train.squeeze()"
      ],
      "metadata": {
        "id": "Yh82wZpseUyB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = train_model(model, X_train=X_train, Y_train=Y_train, num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "wPi3-nLjFyZy",
        "outputId": "281d9d88-3b90-40b7-a2eb-1276f4f3a632"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train model, X_train.shape=(5480, 128, 128, 2)\n",
            "device = cuda\n",
            "X_train.shape = (5480, 128, 128, 2)\n",
            "X_train.shape[0] = 5480\n",
            "minibatch_size = 5\n",
            "minibatch_size = 5\n",
            "type(x_batch_np) 1 = <class 'numpy.ndarray'>\n",
            "x_batch_elem_size = 4\n",
            "x_batch_numel = 163840\n",
            "x_batch_mem_usage = 655360\n",
            "y_batch_elem_size = 4\n",
            "y_batch_numel = 81920\n",
            "y_batch_mem_usage = 327680\n",
            "type(x_batch) 2 = <class 'torch.Tensor'>\n",
            "x_batch shape = torch.Size([5, 128, 128, 2])\n",
            "type x 1 = <class 'torch.Tensor'>\n",
            "x shape 1 = torch.Size([5, 128, 128, 2])\n",
            "type x 2 = <class 'torch.Tensor'>\n",
            "x shape 2 = torch.Size([5, 32768])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f01eb0eeb092>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-93bbc637b071>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, Y_train, learning_rate, num_epochs, minibatch_size)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-93bbc637b071>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_H0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_W0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[5, 1, 128, 128]' is invalid for input of size 163840"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}